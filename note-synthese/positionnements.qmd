::: {#exergue-Positionnements1 .exergue}
« Il y a partout\
des forces qui constituent\
des micro-cerveaux. »\
[@deleuze2005, p. 200]
:::

::: {#exergue-Positionnements2 .exergue}
« Le numérique est donc\
à la fois ce qui est\
autour de nous,\
entre nous,\
en nous »\
[@bachimont2020]
:::

# Positionnements {#sec-positionnements}

Où suis-je ?  Quels sont les textes fondateurs, les cadres épistémologiques, les influences et leurs ramifications qui constituent aujourd'hui mon milieu de connaissances et dans lesquels évoluent ma pensée ?

Pour répondre à ces questions nous explorerons les auteurs qui m'ont influencés, les paysages scientifiques que j'ai parcourus et qui m'ont amené à découvrir et cultiver mon écosystème de connaissances. Ce chapitre présente mon point de vue sur cet écosystème, c'est à-dire d'où je le regarde, avec quel niveau de précisions et pour en dire quoi. Nous donnerons une représentation de ce que je discerne dans la noosphère [@chardin1997; @morin1981] et comment j'y agis. Ce milieu de connaissances est composé par les documents que j'ai consultés au fil des années mais aussi par les personnes avec lesquelles les échanges intellectuels m'ont ouvert à de nouveaux espaces de connaissances. Le troisième élément qui compose cette environnement est constitué par les concepts qui ont émergé de mes expériences. Le quatrième élément est l'ensemble des rapports que je compose avec les documents, les personnes et les concepts.

Dans cette partie nous détaillerons notre parcours intellectuel depuis notre entrée à l'université jusqu'à notre thèse. Puis, nous exposerons les processus de veille que nous avons mis en place pour cultiver notre écosystème de connaissances. A partir des résultats de cette veille, nous montrerons quelles sont nos positions dans le domaine des sciences humaines et plus spécifiquement en science de l'information et de la communication en utilisant les principes de cartographie des connaissances que nous détaillerons plus loin @sec-principesCarto.

## Parcours initiaux {#sec-parcoursinitiaux}

[^positionnements-1]De l'histoire de l'art aux sciences de l'information et de la communication mon parcours intellectuel m'a donné tout d'abord la chance de découvrir l'art et d'apprendre à voir par la pratique intensive des œuvres et leurs analyses complexes. Plus particulièrement, lors de mes recherches en [maîtrise d'histoire de l'art sur la gravure au XVIIIe siècle](http://localhost/samszo/omk/s/fiches/item/299343) j'ai analysé à travers une exploration des catalogues de ventes, comment un des premiers réseau de diffusion à grande échelle des images contribuait à l'histoire du goût. Ce premier travail de recherche m'a sensibilisé à l'importance des bases de données documentaires pour les recherches et ou outils nécessaires pour les exploiter efficacement. Sans le savoir à l'époque, je commençais mon exploration des humanités numériques que je continuais dans mon travail de [DEA](http://localhost/samszo/omk/s/fiches/item/299342) sur l'influence de John Cage en menant une première expérimentation sur la cartographie des affinités[@rodighiero2021]. Cette recherche m'a fait découvrir quatre notions fondamentales des théories du chaos  : les catastrophes [@thom1975], les objets fractals de Mandelbrot, les attracteurs étranges selon Ruelle et les structures dissipatives selon Prigogine [@gleick1999]. Surtout, j'ai compris les rapports intimes entre ces notions et les sciences humaines à travers mes lectures simultanées de [@foucault1990; @deleuze1988; @guattari1992] et comment ces phénomènes relèvent de la complexité [@morin1981; @morin1985; @morin1992; @morin1995; @morin2001; @morin2006]. De cette période date mes premières rencontres intellectuelles d'importances au centre Thomas More du couvent de la Tourette [@cavalin2017] où j'ai eu la chance de discuter avec [Michel Serres](http://localhost/samszo/omk/s/fiches/item/61108), [Regis Debray](http://localhost/samszo/omk/s/fiches/item/61970), [Michel Pastoureau](http://localhost/samszo/omk/s/fiches/item/541197), [Pascal Ory](http://localhost/samszo/omk/s/fiches/item/541243) et les frères dominicains... C'est à cette période aussi que je mène mes premières expériences de générations hypertextuelles avec le logiciel Hypercard[^positionnements-2] et que je découvre comment le chaos informatique est utile aux sciences humaines en ayant l'intuition d'une machine à stimuler les connaissances par une mise en situation synesthésique...

[^positionnements-1]: Ce chapitre reprend les éléments historiques déjà présenté dans ma thèse [@szoniecky2012]

[^positionnements-2]:
    > https://fr.wikipedia.org/wiki/HyperCard

![Application Hypercard pour la génération automatique de textes philosophiques](media/1000000100000263000001CB6B57709BAD5234C1.png){#fig-appliHypercard fig-align="center"}

Curieux d'explorer plus précisément cette intuition, je me lance dans une thèse grâce à ma rencontre avec [Jean-Pierre Balpe](http://localhost/samszo/omk/s/fiches/item/61153) et [Imad Saleh](http://localhost/samszo/omk/s/fiches/item/61148) qui m'encouragent à travailler sur la conception d'agents autonomes pour générer des hypertextes adaptatifs. Trop autonome, je ne réalise pas à l'époque l'importance de travailler collectivement dans un laboratoire de recherche, je parts en voyage et mène mes recherches de manière solitaire jusqu'à ce que dix ans plus tard je retrouve Jean-Pierre et Imad. Fort de nouvelles expériences comme consultant spécialiste en système d'information et en développement Web (cf. [Carrière privée](http://localhost/samszo/omk/s/fiches/item/300719)), je reviens à l'université pour cette fois participer activement à la vie du [laboratoire Paragraphe](http://localhost/samszo/omk/s/fiches/item/299601), tout d'abord comme conférencier puis chargé de cours et professeur contractuel. L'opportunité d'un contrat doctoral me permet de mener à bien une thèse sous la direction d'[Imad Saleh](http://localhost/samszo/omk/s/fiches/item/61148) et de m'inscrire pleinement dans une [carrière universitaire](http://localhost/samszo/omk/s/fiches/item/300716) que je mène comme Maître de conférence en science de l'information et de la communication depuis 2013.

L'atmosphère très fertile au sein de Paragraphe et les relations intenses que ce laboratoire entretient avec la communauté des sciences de l'information et de la communication, a stimulé l'engagement de mes recherches dans de multiples collaborations en France et à l'étranger @fig-collabMondeSamszo. Celles-ci m'ont permis de découvrir des milieux et des pratiques très diverses, par exemple en collaborant avec des institutions prestigieuses comme la Bibliothèque Nationale de France, les Archives Nationales ou l'INA, avec des programmes de recherche ANR comme Biolographes ou Aliento, avec des projets de recherches internationaux comme Arcanes, avec des groupes de recherches comme GENIC ou MANEP, avec des enjeux sociétaux importants comme celui de l'accessibilité, de l'écologie ou de l'éthique.

La participation dès l'origine à trois Projets d'Investissement d'Avenir (PIA) que sont le laboratoire d'excellence H2H, l'IDEFI CréaTIC et l'EUR ArTec, m'a donné la chance de découvrir des projets importants tout à la fois en terme de gouvernance de la recherche que de possibilité d'expérimentation. De même, mon implication dans les instances de l'Université Paris 8 en tant que membre du Conseil Documentaire du SCD, du conseil pédagogique de l'UFR STN et de la commission de spécialistes en Science de l'Information et de la Communication, me donne une bonne connaissance des rouages nécessaires et des difficultés qu'il faut surmonter pour que les activités de recherche et la vie des institutions se développent.

Grâce à ces activités, j'ai eu la chance de dialoguer avec de très nombreux chercheurs dont la liste complète serait trop longue à faire figurer ici mais que je remercie vivement pour ces conversations où l'échange de points de vue parfois très différents donnent à la recherche un goût à la fois subtile, surprenant et aventureux. Une première vision de ces relations est visible dans le diagramme ci-dessous qui montre l'évolution de mes productions scientifiques déposé dans HAL suivant deux catégories : celle des mots clefs utilisés pour décrire ces dépôts et celle des collaborateurs ayant participé à la production :

![Evolution des productions](images/steamHALsamszo.png){#fig-steamHalSamszo fig-align="center"}

On le voit, l'essentiel des productions se font avec des collègues du Laboratoire Paragraphe notamment à cause des proximités géographiques mais aussi grâce aux affinités intellectuelles et aux perspectives communes. Toutefois, ce graphique est l'arbre qui cache une forêt beaucoup plus dense car il ne montre pas les relations que j'entretiens avec les collègues avec qui je partage des évènements scientifiques. De même concernant l'évolution des concepts en lien avec mes productions qui dans ce diagramme ne présente qu'une toute petite partie du paysage sémantique que j'explore. Je vous propose d'appronfondir cette exploration en explicitant mon parcours à travers quelques exemple de publications puis en analysant ce paysage à partir de ma veille informationnelle.

## Mon parcours en Sciences de l'information et de la communication {#sec-posiSIC}

Les sciences de l'information et de la communication ont pour but entre autres de concevoir, expérimenter et critiquer des modèles conceptuels permettant de quantifier l'information et de qualifier la communication. Ce double aspect des SIC est sans doute caricatural mais il pose à mon sens les deux pôles entre lesquels cette discipline est en tension. D'un coté nous avons dans la continuation de Shannon, Weaver et des technologies de l'information, une recherche sur les moyens de modéliser l'information pour fournir la matière nécessaire au développement de technologies stables. De l'autre coté, en relation avec les sciences humaines, nous avons dans la continuation des études en communication, une recherche sur l'analyse des pratiques d'échanges. Nous développons ces deux pôles des SIC dans nos enseignements et dans nos recherches.

Mon travail de thèse a été l'occasion de théoriser mes intuitions sur l'utilité de l'informatique et des langages formels pour le travail collectif en sciences humaines et plus spécifiquement dans les sciences de l'information et de la communication. A partir de cette thèse, des ouvrages et des articles qui ont suivis, j'ai élaboré une méthode générique pour la modélisation onto-éthique des écosystèmes de connaissances. Cette méthode s'articule autour d'un diagramme représentant quatre dimensions existentiels : matérielles @sec-espaceMateriels, sociales @sec-espaceActant, conceptuelles @sec-espaceConceptuels et rapports @sec-rapportsInstExis. L'objectif est d'utiliser ce diagramme pour modéliser des « manières d'être » dans un espace-temps spécifique ou pour dire autrement de décrire un point de vue spécifique et ces évolutions dans un écosystème de connaissances.

Cette méthode de modélisation et d'analyse de l'information et de la communication est mise en pratique dans des cours et des projets de recherche. Les objectifs pédagogiques principaux de ces cours sont :

-   comprendre les principes de complexité,

-   abandonner la démarche d'exhaustivité au profit des choix nécessaires à la problématisation,

-   dépasser la difficulté de choisir le statut de l'information,

-   respecter des contraintes formelles par soucis d'interopérabilité.

Plusieurs projets de recherche m'ont permis d'expérimenter cette méthode pour laquelle j'ai conçu et développé des prototypes informatiques spécifiques. Ces expériences me sont très utiles pour évaluer en quoi la méthode est générique, compréhensible et utilisable @sec-part-technoIntello.

De ces expérimentations un programme de recherche se dégage qui vise plusieurs objectifs. Premièrement diffuser le modèle onto-éthique en publiant des recueil de diagrammes composés dans les cours et les projets de recherche. Parallèlement, les applications développées pour la modélisation seront documentées et le code mis à disposition de la communauté des chercheurs et des développeurs. Le modèle sera aussi diffusé dans un séminaire de recherche sur la modélisation des connaissances en sciences humaines, ouvert aux chercheurs réalisant un corpus numériques et désirant employer des méthodes d'Humanités Numériques innovantes. L'objectif est d'accompagner les chercheurs pour modéliser des recherches en humanités numériques en diffusant des bonnes pratiques et des outils efficaces. Deuxièmement, développer des outils intellectuels pour cartographier les connaissances en concevant des interfaces simples et modulaires pour :

-   calculer la complexité de points de vue,

-   cartographier le flux d'information et de communication,

-   modéliser graphiquement une existence informationnelle dans un écosystème de connaissances,

-   stimuler des explorations cognitives en générant des frayages intellectuels,

-   recommander des conversations créatrices.

Pour illustrer cette démarche nous présentons ci-dessous un résumés des publications qui nous semble les plus représentatives.

### 2018 ***Écosystème de connaissances, méthode de modélisation et d'analyse de l'information et de la communication***

A destination des étudiants de Master, cet ouvrage présente les principes de base de la méthode que j'ai conçu pour modéliser et analyser l'information et la communication. J'y présente dans une première partie l'intérêt de concevoir l'information et la communication en tant qu'écosystème et les principes fondamentaux de modélisation qu'on en déduit. La deuxième partie est une mise en pratique des principes théorique à travers des exemples concret d'usages de la méthode.

### 2019 ***Métamorphoses et hybridations d'une archive numérique pour sa valorisation: Vers des écosystèmes de connaissances***

Cet article présente un projet de recherche mené dans le cadre d'un atelier laboratoire CreaTIC pour expérimenter le développement d'une intelligence collective entre les étudiants de l'université Paris 8 et les millions de documents conservés dans les bâtiments de Archives Nationales. L'article montre comment décrire un processus de numérisation en terme de métamorphose et d'hybridation d'un écosystème de connaissance. Il présente des outils pour un « culture intensif » de l'information et un prototype développé dans le cadre de ce projet pour « le jardinage collectif des connaissances ».

### 2019 ***Espace liminaire de l'authenticité: Une démarche d'humanités numériques***

L'activité automatisée de production de faux, tels que les ​fake news​ et le ​deepfake​, engendre des répercussions dans l'espace social tangible et concernent les relations de confiance que nous construisons quotidiennement avec l'information qui nous parvient. Cet article traite de la transformation de l'espace de médiation et cherche à comprendre la redéfinition actuelle et futures des notions d'authenticité et d'autorité liées à l'accord de la légitimité. Il porte aussi sur le dialogue performatif des données et des actions collectives d'utilisateurs.

### 2019 ***Knowledge Design in the Internet of Things : Blockchain and Connected Refrigerator***

L'Internet des objets fait partie de notre vie quotidienne, mais de nombreux utilisateurs ne comprennent pas les relations de ces objets avec les réseaux numériques, ni les données qui transitent à partir des usages qu'ils en font. Dans cet article, nous supposons que les représentations dynamiques et interactives du pouvoir d'action des utilisateurs et des objets sont des moyens de mieux comprendre de quoi ces dispositifs sont capables. Pour ce faire, nous concevons une conception sécurisée et respectueuse de la vie privée des connaissances dans l'environnement des objets connectés. Nous analysons l'exemple d'un réfrigérateur connecté pour comprendre comment utiliser la Blockchain pour développer des Innovations Sociales Numériques.

### 2020 ***Conception d'un crible pour mesurer collectivement les impacts écologiques de l'activité***

Cet article présente une méthode pour concevoir un dispositif générique de métrologie citoyenne que nous appelons crible et dont nous étudions la conception dans le contexte de l'écologie de l'activité, plus précisément dans l'exemple de la consommation d'avocat. Cette conception s'appuie sur une modélisation éthique de l'activité faisant référence à [@guattari1989; @deleuze1988; @µ2015; @citton2008][@descola2005; @berque2009] et s'appuyant sur les exigences qu'une telle démarche implique pour la gestion des données. Le crible en tant qu'interface entre objectivité et subjectivité offre une analogie opératoire pour explorer les conséquences de l'activité à partir d'un modèle simple d'écriture et de lecture basée sur la formule logique sujet -- objet - prédicat contrainte par l'ontologie éthique : physicalités, acteurs, concepts, rapports.

Ces publications donnent un bon aperçu de mon parcours depuis ma thèse mais il peut être présenter de manière encore plus précise à partir des résultats de ma veille informationnelle.

## Processus de veille pour créer une base de connaissances {#sec-processusVeille}

Depuis une quinzaine d'années, je mène un veille active pour à la fois trouver, filtrer, organiser et diffuser les informations pertinentes pour mes travaux de recherche et d'enseignement. Au fil du temps, j'ai mis en place un processus spécifique pour effectuer cette tâche le plus efficacement possible. Ce processus s'inspire des pratiques professionnelles [@andro2022] que j'adapte pour consacrer à ce travail une matinée par semaine.

### Sélectionner des sources {#sec-selectSources}

La première étape de ce processus de veille consiste à sélectionner des sources d'informations qui me semble pertinentes pour explorer un domaine de connaissances. Pour ce faire, j'utilise principalement deux types de sources : des e-mails et des flux RSS.

J'utilise les e-mails pour recevoir périodiquement des informations soit en m'abonnant à des newsletters[^positionnements-3] et des forums[^positionnements-4], soit en utilisant le services d'alertes proposé par Google, Google Scholar et HAL[^positionnements-5]. Pour les alertes, j'en ai paramétré une cinquantaine portant soit sur des noms de chercheur soit sur des concepts. La veille sur les noms de chercheur permet de connaître les nouvelles publications de cette personne mais aussi comment il est cité par d'autres chercheurs. Les alertes sur les concepts donne une bonne idée de l'activité informationnelle dans un domaine. J'utilise aussi le service de CAIRN pour recevoir automatiquement les nouvelles parutions des revues scientifiques qui m'intéresse.

[^positionnements-3]:
    > Liste des newsletters : https://bit.ly/3KhDwY9

[^positionnements-4]:
    > Liste des forums : https://bit.ly/44KPfGX

[^positionnements-5]:
    > Liste des alertes : https://bit.ly/3KgkSjz

Pour consulter les flux RSS[^positionnements-6] que j'ai sélectionnés, j'utilise l'agrégateur de flux Netvibes[^positionnements-7] qui permet une lecture rapide des flux à partir du titre des articles. Notons que la durée de vie d'un flux RSS est relativement limité puisque sur le 180 flux que j'ai sélectionnés plus de la moitiés ne sont plus opérationnels. Par exemple, le site d'Amazon ne met plus à disposition de flux RSS pour suivre les parutions d'ouvrage dans un domaine spécifique.

[^positionnements-6]:
    > Liste des flux RSS : https://bit.ly/3Yd9Z7V

[^positionnements-7]:
    > https://www.netvibes.com/

### Filtrer les informations {#sec-filtrerInfos}

La deuxième étape du processus de veille consiste à filtrer les informations que les sources transmettent. Comme je reçois beaucoup d'information des sources, le filtrage doit être rapide. Pour ce faire, j'utilise un navigateur Web pour à la fois consulter les informations fournies par les sources et accéder aux détails de celles-ci. Le premier filtre se fait par une lecture des titres et parfois du résumé afin de déterminer si l'information est pour moi pertinente ou pas. Si elle l'est, j'active le lien hypertexte pour ouvrir dans un nouvel onglet les détails. Quand j'ai fini la lecture de la source, je consulte les onglets ouverts pour confirmer le filtrage et le cas échéant annoter cette nouvelle référence.

### Annoter les références {#sec-annoterReference}

L'étape d'annotation des références est très importante car elle consiste à enregistrer les informations pour enrichir ma base de connaissances. Pour effectuer cette troisième étape du processus, j'utilise deux outils complémentaires. Pour ce qui concerne les données bibliographiques non numérisées, j'ai fait le choix de Zotero pour enregistrer les références de la données et les annoter avec une liste de mots clefs et des citations du document dans des notes. Notons que Zotero ajoute automatiquement des mots clefs lorsque ceux-ci sont précisés dans les métadonnées du document. Concernant les données du Web, j'utilise l'outil d'annotation Diigo[^positionnements-8] pour non seulement enregistrer l'URL d'un document Web mais aussi le décrire avec des mots clefs, surligner avec différentes couleurs une partie du document pour l'extraire et la commenter, faire des copies d'écran pour conserver une partie de la page visualisée.

[^positionnements-8]:
    > https://www.diigo.com/index

En terme d'indexation, cette étape d'annotation enregistre les rapports entre des informations physiques concernant les références d'un document et de ses parties, des informations conceptuelles à travers les mots clefs utilisés, des informations sur l'actant qui fait l'annotation à un moment donnée.

### Utiliser les annotations {#sec-utiliserAnnotations}

L'usage le plus fréquent que je fais des annotations consiste à référencer nos écrits scientifiques en utilisant des URLs ou des données bibliographiques que j'intégre directement dans le texte grâce au connecteur Zotero[^positionnements-9], comme c'est le cas dans ce travail. Les références enregistrées dans ma base de connaissances se retrouvent facilement en faisant une recherche par mot clef ou en plein texte. Les résultats de ces recherches donnent une liste de documents dont les annotations font office de résumé. En visualisant les mots clefs utilisés et les parties sélectionnées, il n'est plus nécessaire de consulter l'intégralité du document. Par exemple, voici la page d'annotation d'un article dans Diigo :

[^positionnements-9]:
    > https://tutos.bu.univ-rennes2.fr/c.php?g=686436&p=4906338

![Article annoté dans Diigo](media/10000001000003A4000002648983E64502CE7461.png){#fig-annotationDiigo fig-align="center"}

Cette copie d'écran montre les parties de l'article que j'ai sélectionnées (marge jaune) et les notes que j'ai prises pour la sélection (marge grise). En ce référent à cette page d'annotation, il est pratique de retrouver rapidement ce qui m'a semblé pertinent et pourquoi[^positionnements-10].

[^positionnements-10]:
    > J'ai testé avec plusieurs groupes d'étudiants, l'association d'une couleur de surlignage avec une signification particulière : vert = je suis d'accord, rouge = je ne suis pas d'accord, jaune = je ne comprend pas et bleu = référence. L'expérience est toujours en cours et les résultats seront bientôt publiés.

Un autre usage particulièrement intéressant des annotations est la conservation des références qui ne sont plus accessibles en ligne et qui représente dans notre corpus plus de 10 % des URL (cf. ci-dessous). Lorsque nous importons les annotations Web depuis Diigo vers ma de base de connaissances Omeka S @sec-importDiigo, je teste la validité de l'URL et enregistre son statut[^positionnements-11] ce qui permet de savoir quelles URL sont obsolètes :

[^positionnements-11]:
    > https://samszo.univ-paris8.fr/omk/api/references?metadata\[serverStatus\]=schema:serverStatus

![Répartition de la classe des statuts pour les URL dans Diigo](media/10000001000001E6000001FDFBA335D820BED6E2.png){#fig-statutUrlDiigo fig-align="center"}

L'usage le plus intéressant de cette base de données d'annotations est sans doute leurs analyses pour une gestion des connaissances personnelles [@deuff2012] et la cartographie d'un milieu de connaissance qui est l'objet de ce travail.

De manière plus expérimentale, nous utilisons ces annotations pour développer de nouvelles formes d'éditorialisation scientifiques en puisant dans cette base de données la matière d'une inspiration chaotique @sec-chaoticumSeminario.

### Diffuser les annotations {#sec-diffuserAnnotations}

Ce travail d'annotation et de sélection de citation me fourni une base de connaissances de plus de 1 400 références bibliographiques et plus de 19 000 références Web qui sont indexées par plus de 6 000 concepts. L'ensemble de ces données sont accessibles soit sur les Zotero pour les références bibliographiques[^positionnements-12], soit sur Diigo pour les références Web[^positionnements-13], soit directement dans mon site Omeka S dans un format HTML pour naviguer dans la base de données ou en JSON[^positionnements-14] pour analyser les données avec des algorithmes.

[^positionnements-12]:
    > https://www.zotero.org/luckysemiosis/library

[^positionnements-13]:
    > https://www.diigo.com/user/luckysemiosis

[^positionnements-14]:
    > https://samszo.univ-paris8.fr/omk/api/items?item_set_id=1&item_set_id=4

### Réfléchir le processus {#sec-reflechirProcessus}

Le processus que nous venons de décrire évolue constamment, tend à s'améliorer, se préciser au fil du temps et s'enrichir de nouvelles pratiques. Par exemple, une analyse automatique de l'adéquation entre les sources d'information, les données filtrées, les annotations et leurs utilisations dans des travaux scientifiques ou pédagogiques, pourrait servir de base pour un système de recommandation [@hachour2014].

Toutefois, le fait que les étapes du processus soient principalement manuelles contribue à construire une subjectivité qui m'est propre. Chaque décision nécessaire pour la poursuite du processus est prise parce qu'au moment du choix elle correspond aux inclinaisons de ma « raison trajective » @fig-cyclesemiose . En enregistrant ces décisions via des dispositifs numériques, le processus de veille offre dès lors un triple intérêt. Premièrement, il permet d'explorer rationnellement une domaine de connaissances. Deuxièmement, elle trace un frayage [@citton2010] particulier dans un écosystème de connaissances qui crée les conditions d'une communication stigmergique :

> « L'étymologie grecque explique assez bien le sens du mot « stigmergie » : des marques (stigma) sont laissées dans l'environnement par l'action ou le travail (ergon) de membres d'une collectivité, et ces marques guident en retour -- et récursivement -- leurs actions. » [@lévy2023]

Troisièmement, il donne une représentation d'une subjectivité et de ces évolutions ce qui conditionne le développement de la réflexivité et de l'esprit critique [@desfrichesdoria2021].

Entre l'automatisation du processus et les choix manuels, il convient donc de pratiquer le bon équilibre entre alléger le travail et construire son esprit critique @sec-part-technoIntello.

## Cartographie existentielle de ma base de connaissances

A partir du processus de veille que nous venons de décrire, j'ai constitué une base de connaissances qui reflète de manière très précise mon environnement scientifique et intellectuel. Pour faciliter le traitement des données de cette environnement nous les avons centralisées dans Omeka S qui représente une base de données SQL de 75 tables peuplées par plus de 2 000 000 de lignes[^positionnements-15]. Le graphique ci-dessous présente la répartition des objets disponibles dans cet écosystème suivant leur classe[^positionnements-16] :

[^positionnements-15]: L'ensemble de ces données sont accessibles via l'API de Omeka S sous un format RDF-JSON utilisé pour l'interopérabilité entre les machines mais aussi via des représentations dédiées à la navigation à l'intérieur de cet écosystème.

[^positionnements-16]:
    > Les données de ce graphique et d'autres statistiques sont disponibles ici : \<omkStats.html\>

![Répartition des classes par nombre d'objet dans l'écosystème](media/100000010000023E0000017E87A6A293BEC71C5E.png){#fig-repartitionClass width="11.09cm" height="7.378cm"}

Le graphique montre que les deux tiers des objets dans l'écosystème sont des annotations (61 120 = 60 %) qui créent un rapport entre un document, un actant et un concept. Nous retrouvons ici le 4 dimensions du modèle que nous utilisons pour modéliser les connaissances (@sec-modeleOntoEthique) : document, actant, concept, rapport. Plus précisément, la dimension physique (documentaire) est composée essentiellement de pages Web (19 491 items = 19 %[^positionnements-17]), des citations (8 994 = 9 %), de médias (3 427 = 3 %), des notes (1 488 = 1 %) et des livres (568 = 1 %) issues de notre processus de veille. Les autres dimensions de l'écosystème sont les concepts (6 266 = 6 %) et les personnes (1 898 2 %) associées aux actants (500 = 0,5 %). Le graphique ci-dessous montre cette répartition des objets suivant les dimension existentielles :

[^positionnements-17]:
    > Liste complète des pages Web : <https://bit.ly/3Qj1NRm>

![Répartition des objets par dimension existentielle](media/100000010000021900000181A00CD43E3311E6DF.png){#fig-repartitionDimExi width="11.185cm" height="8.019cm"}

Cette représentation suivant la classe des objets sous estime la complexité de l'écosystème puisqu'elle ne prend pas en compte le détails des valeurs (dimension physique) de chaque propriété (dimension concept) ni l'actant qui exprime les rapports entre propriétés et valeurs, encore moins l'évolution de cette complexité au fur et à mesure que l'écosystème se transforme. Pour une meilleur compréhension de l'écosystème, nous considérons chaque donnée comme une existence particulière qui possède ça propre complexité qui s'ajoute à la complexité de l'ensemble. Cette complexité de l'objet est d'autant plus grande que la valeur d'une propriété est une ressource sous la forme d'une URI vers une page Web ou un lien vers une autre existence de l'écosystème est donc vers une nouvelle complexité qui elle aussi s'ajoute à la complexité globale. A partir des règles génériques pour calculer la complexité existentielle d'un écosystème (@sec-complexiteExitentielle), nous obtenons pour l'écosystème de connaissances de ce travail une complexité de 38.4589 Millions, ce qui est très important en comparaison de la complexité d'une citation d'ouvrage qui varie entre 60 et 3 000 mais ce qui est très peu par rapport à la complexité d'une bibliothèque, de wikipédia ou d'une IA générative comme ChatGPT (@sec-modeliserEcosystemeReference). Ce chiffre prend en compte l'ensemble des existences informationnelles qui peuplent notre base de connaissance, il nous est utile pour comparer les connaissances potentielles de ces existences dont on peut représenter la répartition suivant leur niveau de complexité (abscisse) et le nombre d'existence pour chaque complexité (ordonné) :

![Répartition de la complexité des existences dans l'écosystème [voir en ligne](pulsationsExistentielles.html)](images/localhost_samszo_HDR_jdcComplexity.html.png){#fig-RepartitionComplexity fig-align="center"}

Ce graphique montre que la complexité des existences est très diverse puisqu'elle s'établit entre 1 et presque 3 Millions, de même concernant le nombre d'existence ayant la même complexité qui oscille entre 1 et plus de 10 mille. Une analyse des répartitions suivant le type de ressource omeka (media, item, collection, annotation) montre que les ressources les moins complexes sont les médias avec une complexité inférieure à 12 et les plus complexes sont bien évidemment les collections car elles cumulent les complexités des ressources qui la compose.

Il reste encore de nombreuses travaux de recherche à faire sur cet écosystème de connaissances, ces évolutions,les moyens de les modéliser et de les analyser. Le chapitre suivant donne un exemple de ce type de travaux en analysant les personnes présente dans l'écosystème.

## Analyse qualitative des personnes de l'écosytème